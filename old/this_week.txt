What have I done this week?
- Some rearrangement of data to make csv files for all the americasnlp languages and spanish (except maybe aymara oops)	
    • this made it easier to read everything as we were doing it for rus-tyv

- trained and tested rus-tyv with the larger dataset (123k although I think it’s only around 117k)
    • kind of surprising results here- the one trained and tested with the standard tokenizer 
      did better than the one with the custom one

- refactored some of the train.py and evaluate.py code to include command line arguments 
  for the save path and languages and stuff 

- in general, some attempt at organization and cleaning, though I think I’ve come to some
  better conclusions now that aren’t yet implemented

- added patience parameter

- made evaluate.py write to file with date and time and some info

- made train.py log some info as well - shows up in log_<pid>.out

- trained and tested all the americasnlp languages with the 1.3B model- results are in results.txt
  and are pretty good- some observations here on overfitting and such:
    • the low resource language pairs seem to only save the model at the first one or two
      checkpoints - 1,000 and 2,000 updates.
    • I think then it would be good to have the checkpoints closer together for lower-resource pairs just to optimize a little
      haven't done that yet


Some conclusions:

1. The question of which language code to use is still a little unresolved...
and I haven't been too neat about it in code. I don't know how important it is that
a language pair be trained and evaluated with the same lang code, but it seems like it should be like that....
At some point I switched from using guarani as the default to quechua because there's a lot more quechua data... 
again i'm kind of guessing here. I did a little googling about the relatedness of some of the languages but 
didn't have a system really

2. I think the best way to streamline the code for training and testing is just to have the train program 
log some information in a new file in the model directory, then call the evaluation program. They can still be 
separate so we can evaluate at any point. Then I think I should refactor some of the eval code because the command
line arguments will be redundant if there is a file with info about the model/training. arrived at this conclusion 
fairly late so I haven't done that yet

quick question - a few times (maybe on saturday or sunday) I couldn't run the evaluation program 
just on its own because the gpu was out of memory or something. So I had to submit a few as slurm jobs
Seemed like running it from command line was using GPU 0 when that was being used already. Anything I can do there?